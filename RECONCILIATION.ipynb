{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7cd892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca350b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate the directory where the excel files are\n",
    "excel_dir = r'C:\\Users\\LENOVO\\Documents\\python\\recon\\ATS T24'\n",
    "excel_dir1 = r'C:\\Users\\LENOVO\\Documents\\python\\recon\\INWARDS'\n",
    "excel_dir2 = r'C:\\Users\\LENOVO\\Documents\\python\\recon\\OUTWARDS'\n",
    "excel_dir3 = r'C:\\Users\\LENOVO\\Documents\\python\\recon\\ATS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492aced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the os module to list all files inn the directory\n",
    "all_files = os.listdir(excel_dir)\n",
    "all_files1 = os.listdir(excel_dir1)\n",
    "all_files2 = os.listdir(excel_dir2)\n",
    "all_files3 = os.listdir(excel_dir3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12693f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list to store the excel file names\n",
    "excel_files = []\n",
    "excel_files1 = []\n",
    "excel_files2 = []\n",
    "excel_files3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed46c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through all the files and keep only those that end with '.xlsx'\n",
    "for file in all_files:\n",
    "    if file.endswith('.xlsx'):\n",
    "        excel_files.append(file)\n",
    "\n",
    "#loop for inward\n",
    "for file in all_files1:\n",
    "    if file.endswith('.xlsx'):\n",
    "        excel_files1.append(file)\n",
    "        \n",
    "#loop for outward\n",
    "for file in all_files2:\n",
    "    if file.endswith('.xlsx'):\n",
    "        excel_files2.append(file)\n",
    "        \n",
    "#loop for ATS\n",
    "for file in all_files3:\n",
    "    if file.endswith('.xlsx'):\n",
    "        excel_files3.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd6a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "dfs1 = []\n",
    "dfs2 = []\n",
    "dfs3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a70afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through each excel file and read it into a dataframe\n",
    "for file in excel_files:\n",
    "    file_path = os.path.join(excel_dir, file)\n",
    "    df = pd.read_excel(file_path)\n",
    "    dfs.append(df)\n",
    "    \n",
    "#loop for inward\n",
    "for file in excel_files1:\n",
    "    file_path1 = os.path.join(excel_dir1, file)\n",
    "    df1 = pd.read_excel(file_path1)\n",
    "    dfs1.append(df1)        \n",
    "    \n",
    "#loop for outward\n",
    "for file in excel_files2:\n",
    "    file_path2 = os.path.join(excel_dir2, file)\n",
    "    df2 = pd.read_excel(file_path2)\n",
    "    dfs2.append(df2)\n",
    "    \n",
    "#loop for ats\n",
    "for file in excel_files3:\n",
    "    file_path3 = os.path.join(excel_dir3, file)\n",
    "    df3 = pd.read_excel(file_path3)\n",
    "    dfs3.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "340e0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the list of dataframes into one\n",
    "merged_df = pd.concat(dfs, axis = 0, ignore_index = True)\n",
    "\n",
    "#concatenate for inward\n",
    "merged_df1 = pd.concat(dfs1, axis = 0, ignore_index = True)\n",
    "\n",
    "#def make_numeric_negative(x):\n",
    "   # if pd.api.types.is_numeric_dtype(x):\n",
    "      #  return -x\n",
    "   # return x\n",
    "\n",
    "#merged_df1['Unnamed: 7'] = merged_df1['Unnamed: 7'].apply(make_numeric_negative)\n",
    "\n",
    "#concatenate for outward\n",
    "merged_df2 = pd.concat(dfs2, axis = 0, ignore_index = True)\n",
    "\n",
    "#concate for ATS\n",
    "merged_df3 = pd.concat(dfs3, axis = 0, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a8a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df1['Unnamed: 7'] = merged_df1['Unnamed: 7'] * -1\n",
    "#merged_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cc95805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate transfer reference with amount to create a primary key for the the special clearance data\n",
    "merged_df['CONCATENATE'] = merged_df.apply(lambda row:str(row['TRANSACTION REFERENCE']) + '' + str(row['AMOUNT']), axis = 1)\n",
    "\n",
    "#concatenate for inward\n",
    "merged_df1['CONCATENATE'] = merged_df1.apply(lambda row:str(row['Unnamed: 9']) + '' + str(row['Unnamed: 7']), axis = 1)\n",
    "\n",
    "\n",
    "#concatenate for outward\n",
    "merged_df2['CONCATENATE'] = merged_df2.apply(lambda row:str(row['Unnamed: 8']) + '' + str(row['Unnamed: 7']), axis = 1)\n",
    "\n",
    "#concatenate for outward\n",
    "merged_df2['CONCATENATE'] = merged_df2.apply(lambda row:str(row['Unnamed: 8']) + '' + str(row['Unnamed: 7']), axis = 1)\n",
    "#selected_column = merged_df2['CONCATENATE'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d0298bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the special clearance into (+)inward and (-)outward\n",
    "postive_amounts_df = merged_df[merged_df['AMOUNT'] > 0]\n",
    "negative_amount_df = merged_df[merged_df['AMOUNT'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a83be943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122909"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a04f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_15632\\459637228.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  postive_amounts_df['VLOOKUP'] = postive_amounts_df['CONCATENATE'].isin(merged_df2['CONCATENATE']).map({True: 'Yes', False: 'No'})\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_15632\\459637228.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negative_amount_df['VLOOKUP'] = negative_amount_df['CONCATENATE'].isin(merged_df1['CONCATENATE']).map({True: 'Yes', False: 'No'})\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already loaded and processed your dataframes as mentioned in your code\n",
    "\n",
    "# Create a VLOOKUP-like column in negative_amount_df\n",
    "postive_amounts_df['VLOOKUP'] = postive_amounts_df['CONCATENATE'].isin(merged_df2['CONCATENATE']).map({True: 'Yes', False: 'No'})\n",
    "\n",
    "# Create a VLOOKUP-like column in negative_amount_df\n",
    "negative_amount_df['VLOOKUP'] = negative_amount_df['CONCATENATE'].isin(merged_df1['CONCATENATE']).map({True: 'Yes', False: 'No'})\n",
    "\n",
    "\n",
    "# Create a VLOOKUP-like column in negative_amount_df\n",
    "merged_df2['VLOOKUP'] = merged_df2['Unnamed: 6'].isin(merged_df3['Item Reference']).map({True: 'Yes', False: 'No'})\n",
    "\n",
    "# Print the updated negative_amount_df with the 'VLOOKUP' column\n",
    "#postive_amounts_df.head()\n",
    "\n",
    "# Assuming you have already loaded and processed your dataframes as mentioned in your code\n",
    "\n",
    "# Create a VLOOKUP-like column in negative_amount_df\n",
    "#negative_amount_df['VLOOKUP'] = negative_amount_df['TRANSACTION REFERENCE'].isin(merged_df2['Unnamed: 8']).map({True: 'Yes', False: 'No'})\n",
    "\n",
    "# Print the updated negative_amount_df with the 'VLOOKUP' column\n",
    "#positive_amount_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17cea88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame merged_df1 has been saved to C:\\Users\\LENOVO\\Documents\\python\\recon\\ATS T24\\postive_amounts_df_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the output Excel file path OUTWARD\n",
    "output_excel_file = os.path.join(excel_dir, 'postive_amounts_df_output.xlsx')\n",
    "\n",
    "# Save merged_df1 to the output Excel file\n",
    "postive_amounts_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "# Print a message indicating where the file was saved\n",
    "print(f\"DataFrame merged_df1 has been saved to {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3512d5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame merged_df1 has been saved to C:\\Users\\LENOVO\\Documents\\python\\recon\\OUTWARDS\\ats_rec_df_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the output Excel file path ATS\n",
    "output_excel_file = os.path.join(excel_dir2, 'ats_rec_df_output.xlsx')\n",
    "\n",
    "# Save merged_df1 to the output Excel file\n",
    "postive_amounts_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "# Print a message indicating where the file was saved\n",
    "print(f\"DataFrame merged_df1 has been saved to {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be7f2145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame merged_df1 has been saved to C:\\Users\\LENOVO\\Documents\\python\\recon\\ATS T24\\negative_amounts_df_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the output Excel file path for INWARD\n",
    "output_excel_file = os.path.join(excel_dir, 'negative_amounts_df_output.xlsx')\n",
    "\n",
    "# Save merged_df1 to the output Excel file\n",
    "negative_amount_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "# Print a message indicating where the file was saved\n",
    "print(f\"DataFrame merged_df1 has been saved to {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecf80c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'yes' data has been saved to C:\\Users\\LENOVO\\Documents\\python\\recon\\ATS T24\\merged_df_yes_output.xlsx\n",
      "'no' data has been saved to C:\\Users\\LENOVO\\Documents\\python\\recon\\ATS T24\\merged_df_no_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "#extracting the yes nd no separetely \n",
    "yes_output_excel_file = os.path.join(excel_dir, 'merged_df_yes_output.xlsx')\n",
    "no_output_excel_file = os.path.join(excel_dir, 'merged_df_no_output.xlsx')\n",
    "\n",
    "yes_data = postive_amounts_df[postive_amounts_df['VLOOKUP'] == 'yes'] \n",
    "no_data = postive_amounts_df[postive_amounts_df['VLOOKUP'] == 'no']\n",
    "\n",
    "yes_data.to_excel(yes_output_excel_file, index = True)\n",
    "no_data.to_excel(no_output_excel_file, index = True)\n",
    "\n",
    "print(f\"'yes' data has been saved to {yes_output_excel_file}\")\n",
    "print(f\"'no' data has been saved to {no_output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2021cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

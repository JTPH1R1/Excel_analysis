{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b18e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c446f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate the directory where the excel files are\n",
    "excel_dir = r'C:\\Users\\User\\Documents\\New folder\\DS\\final test\\Special Clearance'\n",
    "excel_dir1 = r'C:\\Users\\User\\Documents\\New folder\\DS\\final test\\Inward'\n",
    "excel_dir2 = r'C:\\Users\\User\\Documents\\New folder\\DS\\final test\\Outward'\n",
    "excel_dir3 = r'C:\\Users\\User\\Documents\\New folder\\DS\\final test\\ATS'\n",
    "excel_dir4 = r'C:\\Users\\User\\Documents\\New folder\\DS\\final test\\Reports'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898f87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the os module to list all files inn the directory\n",
    "all_files = os.listdir(excel_dir)\n",
    "all_files1 = os.listdir(excel_dir1)\n",
    "all_files2 = os.listdir(excel_dir2)\n",
    "all_files3 = os.listdir(excel_dir3)\n",
    "all_files4 = os.listdir(excel_dir4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "663b4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list to store the excel file names\n",
    "excel_files = []\n",
    "excel_files1 = []\n",
    "excel_files2 = []\n",
    "excel_files3 = []\n",
    "excel_files4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7582a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through all the files and keep only those that end with '.xlsx'\n",
    "for file in all_files:\n",
    "    if file.endswith('.xlsx'):\n",
    "        excel_files.append(file)\n",
    "\n",
    "#loop for inward\n",
    "for file in all_files1:\n",
    "    if file.endswith('.xlsx'):\n",
    "        excel_files1.append(file)\n",
    "        \n",
    "#loop for outward\n",
    "for file in all_files2:\n",
    "    if file.endswith('.xlsx'):\n",
    "        excel_files2.append(file)\n",
    "        \n",
    "#loop for ATS\n",
    "for file in all_files3:\n",
    "    if file.endswith('.xlsx'):\n",
    "        excel_files3.append(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceeb5b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "dfs1 = []\n",
    "dfs2 = []\n",
    "dfs3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ccff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through each excel file and read it into a dataframe\n",
    "for file in excel_files:\n",
    "    file_path = os.path.join(excel_dir, file)\n",
    "    df = pd.read_excel(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "#loop for inward\n",
    "for file in excel_files1:\n",
    "    file_path1 = os.path.join(excel_dir1, file)\n",
    "    df1 = pd.read_excel(file_path1)\n",
    "    dfs1.append(df1)\n",
    "    \n",
    "#loop for outward\n",
    "for file in excel_files2:\n",
    "    file_path2 = os.path.join(excel_dir2, file)\n",
    "    df2 = pd.read_excel(file_path2)\n",
    "    dfs2.append(df2)\n",
    "    \n",
    "#loop for ats\n",
    "for file in excel_files3:\n",
    "    file_path3 = os.path.join(excel_dir3, file)\n",
    "    df3 = pd.read_excel(file_path3)\n",
    "    dfs3.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd4f766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the list of dataframes into one (spcial clearance)\n",
    "merged_df = pd.concat(dfs, axis = 0, ignore_index = True)\n",
    "\n",
    "#concatenate for inward\n",
    "merged_df1 = pd.concat(dfs1, axis = 0, ignore_index = True)\n",
    "\n",
    "#concatenate for outward\n",
    "merged_df2 = pd.concat(dfs2, axis = 0, ignore_index = True)\n",
    "\n",
    "#concate for ATS\n",
    "merged_df3 = pd.concat(dfs3, axis = 0, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b5700b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the inward amount column into negative\n",
    "merged_df1['Amount'] = merged_df1['Amount'] * -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afbe3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Amount' column to float for positive amounts dataframe\n",
    "merged_df1['Amount'] = merged_df1['Amount'].astype(float)\n",
    "\n",
    "# Convert the 'Amount' column to float for negative amounts dataframe\n",
    "#negative_amount_df['Amount'] = negative_amount_df['Amount'].astype(float)\n",
    "\n",
    "# Convert the 'Amount' column to float for merged_df2 (outward) dataframe\n",
    "merged_df2['Amount'] = merged_df2['Amount'].astype(float)\n",
    "\n",
    "# Convert the 'Amount' column to float for merged_df101 (inward) dataframe\n",
    "merged_df['AMOUNT'] = merged_df['AMOUNT'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc182a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the special clearance into (+)inward and (-)outward\n",
    "postive_amounts_df = merged_df[merged_df['AMOUNT'] > 0]\n",
    "negative_amount_df = merged_df[merged_df['AMOUNT'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f581a1c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20608\\3362310381.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  postive_amounts_df['CONCATENATE'] = postive_amounts_df.apply(lambda row:str(row['TRANSACTION REFERENCE']) + '' + str(row['AMOUNT']), axis = 1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20608\\3362310381.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negative_amount_df['CONCATENATE'] = negative_amount_df.apply(lambda row:str(row['TRANSACTION REFERENCE']) + '' + str(row['AMOUNT']), axis = 1)\n"
     ]
    }
   ],
   "source": [
    "#concatenate transfer reference with amount to create a primary key for the the special clearance data\n",
    "postive_amounts_df['CONCATENATE'] = postive_amounts_df.apply(lambda row:str(row['TRANSACTION REFERENCE']) + '' + str(row['AMOUNT']), axis = 1)\n",
    "negative_amount_df['CONCATENATE'] = negative_amount_df.apply(lambda row:str(row['TRANSACTION REFERENCE']) + '' + str(row['AMOUNT']), axis = 1)\n",
    "\n",
    "#concatenate for inward\n",
    "merged_df1['CONCATENATE'] = merged_df1.apply(lambda row:str(row['Serial Number']) + '' + str(row['Amount']), axis = 1)\n",
    "\n",
    "\n",
    "#concatenate for outward\n",
    "merged_df2['CONCATENATE'] = merged_df2.apply(lambda row:str(row['Serial Number']) + '' + str(row['Amount']), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e6f2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20608\\2835296750.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negative_amount_df['VLOOKUP'] = negative_amount_df['CONCATENATE'].isin(merged_df1['CONCATENATE']).map({True: 'Yes', False: 'No'})\n"
     ]
    }
   ],
   "source": [
    "# Create a VLOOKUP-like column in negative_amount_df\n",
    "negative_amount_df['VLOOKUP'] = negative_amount_df['CONCATENATE'].isin(merged_df1['CONCATENATE']).map({True: 'Yes', False: 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a82704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20608\\1930418314.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  postive_amounts_df['VLOOKUP'] = postive_amounts_df['CONCATENATE'].isin(merged_df2['CONCATENATE']).map({True: 'Yes', False: 'No'})\n"
     ]
    }
   ],
   "source": [
    "# Create a VLOOKUP-like column in negative_amount_df\n",
    "postive_amounts_df['VLOOKUP'] = postive_amounts_df['CONCATENATE'].isin(merged_df2['CONCATENATE']).map({True: 'Yes', False: 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54190711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VLOOKUP-like column in negative_amount_df\n",
    "merged_df2['VLOOKUP'] = merged_df2['Reference'].isin(merged_df3['Item Reference']).map({True: 'Yes', False: 'No'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40882579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame merged_df1 has been saved to C:\\Users\\User\\Documents\\New folder\\DS\\final test\\Reports\\NO_FT_df.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the output Excel file path for INWARD\n",
    "merged_df101 = merged_df1[merged_df1['Serial Number'].isnull()]\n",
    "output_excel_file = os.path.join(excel_dir4, 'NO_FT_df.xlsx')\n",
    "\n",
    "# Save merged_df1 to the output Excel file\n",
    "merged_df101.to_excel(output_excel_file, index=False)\n",
    "\n",
    "# Print a message indicating where the file was saved\n",
    "print(f\"DataFrame merged_df1 has been saved to {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ed265b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter rows where 'Serial Number' column is not empty\n",
    "merged_df102 = merged_df1[merged_df1['Serial Number'].notnull()]\n",
    "\n",
    "# Reset the index of the new DataFrame\n",
    "merged_df102.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "732e628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_value = 51  # Replace with the specific value you want to view\n",
    "\n",
    "# Filter rows where 'DEBIT A/C NUMBER' equals the specific value\n",
    "Debit_settlements = postive_amounts_df[postive_amounts_df['DEBIT A/C NUMBER'] == specific_value]\n",
    "Credit_settlements = negative_amount_df[negative_amount_df['CREDIT A/C NUMBER'] == specific_value]\n",
    "\n",
    "combined_settlements = pd.concat([Debit_settlements, Credit_settlements], axis=0)\n",
    "# Display the rows where 'DEBIT A/C NUMBER' equals the specific value\n",
    "output_excel_file = os.path.join(excel_dir4, 'settlements_df.xlsx')\n",
    "\n",
    "# Save merged_df1 to the output Excel file\n",
    "combined_settlements.to_excel(output_excel_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c81b4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'Debit A/C' and 'Credit A/C' columns do not contain the value 51\n",
    "neg_settlement = negative_amount_df[(negative_amount_df['DEBIT A/C NUMBER'] != 51)]\n",
    "pos_settlement = postive_amounts_df[(postive_amounts_df['CREDIT A/C NUMBER'] != 51)]\n",
    "\n",
    "# Reset the index of the new DataFrame\n",
    "neg_settlement.reset_index(drop=True, inplace=True)\n",
    "pos_settlement.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e32ef644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame merged_df1 has been saved to C:\\Users\\User\\Documents\\New folder\\DS\\final test\\Reports\\ATS_Vlookup.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the output Excel file path ATS\n",
    "output_excel_file = os.path.join(excel_dir4, 'ATS_Vlookup.xlsx')\n",
    "\n",
    "# Save merged_df1 to the output Excel file\n",
    "merged_df2.to_excel(output_excel_file, index=False)\n",
    "\n",
    "# Print a message indicating where the file was saved\n",
    "print(f\"DataFrame merged_df1 has been saved to {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6916eabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame merged_df1 has been saved to C:\\Users\\User\\Documents\\New folder\\DS\\final test\\Reports\\Outward_Vlookup.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the output Excel file path OUTWARD\n",
    "output_excel_file = os.path.join(excel_dir4, 'Outward_Vlookup.xlsx')\n",
    "\n",
    "# Save merged_df1 to the output Excel file\n",
    "pos_settlement.to_excel(output_excel_file, index=False)\n",
    "\n",
    "# Print a message indicating where the file was saved\n",
    "print(f\"DataFrame merged_df1 has been saved to {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b539668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame merged_df1 has been saved to C:\\Users\\User\\Documents\\New folder\\DS\\final test\\Reports\\Inward_Vlookup.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the output Excel file path for INWARD\n",
    "output_excel_file = os.path.join(excel_dir4, 'Inward_Vlookup.xlsx')\n",
    "\n",
    "# Save merged_df1 to the output Excel file\n",
    "neg_settlement.to_excel(output_excel_file, index=False)\n",
    "\n",
    "# Print a message indicating where the file was saved\n",
    "print(f\"DataFrame merged_df1 has been saved to {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fffa17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_values = 'No'  # Replace with the specific value you want to view\n",
    "\n",
    "# Filter rows where 'DEBIT A/C NUMBER' equals the specific value\n",
    "Inward_no = neg_settlement[neg_settlement['VLOOKUP'] == specific_values]\n",
    "outward_no = pos_settlement[pos_settlement['VLOOKUP'] == specific_values]\n",
    "merged_df2 = merged_df2[merged_df2['VLOOKUP'] == specific_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fba79765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20608\\649225484.py:10: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  excel_writer.save()\n"
     ]
    }
   ],
   "source": [
    "output_excel_file = os.path.join(excel_dir4, 'Vlookup_NO.xlsx')\n",
    "\n",
    "excel_writer = pd.ExcelWriter(output_excel_file, engine='xlsxwriter')\n",
    "\n",
    "# Corrected function names\n",
    "Inward_no.to_excel(excel_writer, sheet_name='INWARD NO', index=False)\n",
    "outward_no.to_excel(excel_writer, sheet_name='OUTWARD NO', index=False)\n",
    "merged_df2.to_excel(excel_writer, sheet_name='ATS NO', index=False)\n",
    "\n",
    "excel_writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596d570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
